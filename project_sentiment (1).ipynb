{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\nltk\\twitter\\__init__.py:20: UserWarning: The twython library has not been installed. Some functionality from the twitter package will not be available.\n",
      "  warnings.warn(\"The twython library has not been installed. \"\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from nltk.corpus import wordnet as wn\n",
    "from nltk.corpus import sentiwordnet as swn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from textblob.classifiers import NaiveBayesClassifier as NBC\n",
    "from textblob import TextBlob\n",
    "from nltk.sentiment.util import mark_negation\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from multiprocessing import Pool\n",
    "import warnings\n",
    "warnings.simplefilter('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('train.csv')\n",
    "SAdataset = pd.read_csv('Sentiment-Analysis-Dataset/Sentiment Analysis Dataset.csv', error_bad_lines=False, usecols = [1,3])\n",
    "index0 = SAdataset.loc[SAdataset.Sentiment == 0]['Sentiment'] \n",
    "index1 = SAdataset.loc[SAdataset.Sentiment == 1]['Sentiment'] \n",
    "index0.ix[:] = 'neg'\n",
    "index1.ix[:] = 'pos'\n",
    "SAdataset.loc[index0.index, 'Sentiment'] = index0\n",
    "SAdataset.loc[index1.index, 'Sentiment'] = index1\n",
    "\n",
    "ind_neg = SAdataset[SAdataset.Sentiment == 'neg'].index[:5000]\n",
    "ind_pos = SAdataset[SAdataset.Sentiment == 'pos'].index[:5000]\n",
    "\n",
    "short_SAdataset = SAdataset.loc[np.hstack((ind_neg, ind_pos)), ['Sentiment', 'SentimentText']]\n",
    "\n",
    "X = short_SAdataset['SentimentText']\n",
    "y = short_SAdataset['Sentiment']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "train = [(X_train[index_id], y_train[index_id]) for index_id in y_train.index]\n",
    "test = [(X_test[index_id], y_test[index_id]) for index_id in y_test.index]\n",
    "\n",
    "cl = NBC(train)\n",
    "cl.accuracy(test[:100])\n",
    "\n",
    "data['sentiment'] = 0.0\n",
    "\n",
    "def sentiment_analysis_tweet(classifier, text):\n",
    "    return (cl.prob_classify(text).prob(\"neg\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "number_of_processes = 2\n",
    "with Pool(number_of_processes) as p:\n",
    "    result = p.map(lambda x: sentiment_analysis_tweet(cl, x), data['comment_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data['sentiment'] = result\n",
    "data.to_csv('train_tweets.csv', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most Informative Features\n",
      "   contains(musicmonday) = True              pos : neg    =     48.8 : 1.0\n",
      "           contains(sad) = True              neg : pos    =     39.0 : 1.0\n",
      "         contains(hurts) = True              neg : pos    =     22.1 : 1.0\n",
      "         contains(broke) = True              neg : pos    =     15.3 : 1.0\n",
      "  contains(followfriday) = True              pos : neg    =     13.9 : 1.0\n",
      "          contains(quot) = True              pos : neg    =     13.9 : 1.0\n",
      "  contains(FollowFriday) = True              pos : neg    =     12.5 : 1.0\n",
      "         contains(phone) = True              neg : pos    =     11.5 : 1.0\n",
      "          contains(Love) = True              pos : neg    =     11.0 : 1.0\n",
      "         contains(tried) = True              neg : pos    =     10.6 : 1.0\n"
     ]
    }
   ],
   "source": [
    "cl.show_informative_features() "
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
